# Speech-Emotion-Recognition
Developed a Speech Emotion Recognition system using machine learning to classify emotions from audio data, enhancing user interaction capabilities.
Speech Emotion Recognition (SER) is a field of study in machine learning that aims at recognizing human emotions through audio signals. It can identify basic emotions such as happy, neutral, sad, angry, fear, disgust, etc. based on tone, pitch, rhythm, etc. Speech Emotion Recognition uses the TESS dataset along with the Mel - Frequency Cepstral Coefficient (mfcc) for feature extraction, it uses RNN for classifying emotions coupled with Long Short Term Memory (LTSM). The training also involves iterative epochs, to accurately identify and classify emotions. It follows the procedure by 1st pre-processing the dataset, extracting and then classifying features which finally results in recognizing the emotions that can be used for human-computer interaction, sentiment analysis, and psychological research.Speech Emotion Recognition plays a crucial role in verbal and non-verbal communication. Its applications can be seen in various domains such as human-computer interaction, healthcare, security, and customer service. In the healthcare domain, SER might help monitor patientâ€™s mental health while in security it can be used during the interrogation of criminals whereas in customer service it can used to detect customer feedback using their speech.
